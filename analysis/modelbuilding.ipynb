{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import sklearn.metrics\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import modelbuilderpaardensprong\n",
    "from tweevoortwaalf.paardensprong import Paardensprong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PLAYERNAME = os.getenv(\"playername\")\n",
    "\n",
    "database_url_prod = os.getenv(\"PROD_DATABASE_URL\").replace(\n",
    "    \"postgresql\", \"postgresql+psycopg\"\n",
    ")\n",
    "engine_prod = create_engine(database_url_prod)\n",
    "\n",
    "database_url_dev = os.getenv(\"DATABASE_URL\").replace(\"postgresql\", \"postgresql+psycopg\")\n",
    "engine_dev = create_engine(database_url_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine_prod.connect() as conn:\n",
    "    games = pd.read_sql_query(\n",
    "        \"SELECT * FROM paardensprong.games\", con=conn, index_col=\"game_id\"\n",
    "    )\n",
    "    guesses = pd.read_sql_query(\n",
    "        \"SELECT * FROM paardensprong.guesses\", con=conn, index_col=\"guess_id\"\n",
    "    )\n",
    "\n",
    "guesses_relevant = guesses.set_index(\"game_id\").rename(\n",
    "    columns={\"correct\": \"GuessCorrect\"}\n",
    ")[[\"guess_time\", \"GuessCorrect\"]]\n",
    "\n",
    "df = (\n",
    "    games\n",
    "    # Drop games which have no guess - probably time out because of long loading times\n",
    "    .join(guesses_relevant, how=\"inner\")\n",
    "    .query(\"playername == @PLAYERNAME | game_id == 46\")\n",
    "    .assign(\n",
    "        PuzzleTimeSec=lambda df: (df[\"guess_time\"] - df[\"start_time\"]).dt.seconds,\n",
    "        # The on time is a bit strict; since you need a few seconds typing time\n",
    "        # But that's on purpose: it makes sense to train to have a bit of spare time\n",
    "        # And it helps the model since you have just a few more unsuccessfulls to train on\n",
    "        OnTime=lambda df: df[\"PuzzleTimeSec\"].lt(30),\n",
    "        Success=lambda df: df[\"GuessCorrect\"] & df[\"OnTime\"],\n",
    "    )\n",
    "    # A few answers were given extremely late; probably when reconnecting\n",
    "    .query(\"PuzzleTimeSec < 120\")\n",
    "    .assign(NTimesWordSeenBefore=lambda df: df.groupby(\"answer\").cumcount())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\n",
    "    [\n",
    "        \"start_time\",\n",
    "        \"answer\",\n",
    "        \"startpoint\",\n",
    "        \"direction\",\n",
    "        \"NTimesWordSeenBefore\",\n",
    "        \"Success\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "y = X.pop(\"Success\").astype(int)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = modelbuilderpaardensprong.grid\n",
    "grid.fit(X_train, y_train)\n",
    "pipe = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_columns(columns):\n",
    "    if columns == \"all\":\n",
    "        return len(X_train.columns)\n",
    "    return len(columns)\n",
    "\n",
    "\n",
    "results = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(grid.cv_results_[\"params\"]),\n",
    "        pd.Series(grid.cv_results_[\"mean_test_score\"], name=\"mean_test_score\"),\n",
    "        pd.Series(grid.cv_results_[\"mean_train_score\"], name=\"mean_train_score\"),\n",
    "        pd.Series(grid.cv_results_[\"std_test_score\"], name=\"std_test_score\"),\n",
    "    ],\n",
    "    axis=\"columns\",\n",
    ").assign(\n",
    "    Overfit=lambda df: df[\"mean_train_score\"] - df[\"mean_test_score\"],\n",
    "    columns=lambda df: df[\"columnselection__columns\"].apply(n_columns),\n",
    ")\n",
    "\n",
    "results.sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pipe.predict_proba(X_train)\n",
    "train_logloss = sklearn.metrics.log_loss(y_train, y_pred_train)\n",
    "train_auc = sklearn.metrics.roc_auc_score(y_train, y_pred_train[:, 1])\n",
    "\n",
    "y_pred_proba = pipe.predict_proba(X_test)\n",
    "test_logloss = sklearn.metrics.log_loss(y_test, y_pred_proba)\n",
    "test_auc = sklearn.metrics.roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict_proba(X_test)\n",
    "dummy_logloss = sklearn.metrics.log_loss(y_test, y_pred_dummy)\n",
    "dummy_auc = sklearn.metrics.roc_auc_score(y_test, y_pred_dummy[:, 1])\n",
    "\n",
    "print(\"Log loss:\")\n",
    "print(\" Train - Test  -  Dummy\")\n",
    "print(f\"{train_logloss: .3f} - {test_logloss:.3f} - {dummy_logloss: .3f}\")\n",
    "\n",
    "print(\"AUC:\")\n",
    "print(\" Train - Test  -  Dummy\")\n",
    "print(f\"{train_auc: .3f} - {test_auc:.3f} - {dummy_auc: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = ClassifierExplainer(pipe, X_test, y_test)\n",
    "ExplainerDashboard(explainer).run(port=8051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit final model\n",
    "Fit on total set to use all data, do some quick fatal flaw inspection on probabilities and logical relations between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_estimator = clone(pipe)\n",
    "total_estimator.fit(X, y)\n",
    "\n",
    "X_transformed = X.copy()\n",
    "for transformer in total_estimator.steps[:-1]:\n",
    "    X_transformed = transformer[1].transform(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(total_estimator.predict_proba(X)[:, 0]).plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PartialDependenceDisplay.from_estimator(\n",
    "    total_estimator.named_steps[\"clf\"], X_transformed, features=[0, 1, 2], kind=\"both\"\n",
    ")\n",
    "\n",
    "\n",
    "display.plot(pdp_lim={1: (0.8, 1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_puzzle_options(n_per_answer=4):\n",
    "    words = pd.read_csv(\n",
    "        \"../tweevoortwaalf/Data/suitable_8_letter_words.txt\", header=None\n",
    "    ).squeeze()\n",
    "    startpoint = range(8)\n",
    "    directions = [-1, 1]\n",
    "\n",
    "    X_new = pd.DataFrame(\n",
    "        itertools.product(words, startpoint, directions),\n",
    "        columns=[\"answer\", \"startpoint\", \"direction\"],\n",
    "    )\n",
    "    X_new = X_new.merge(\n",
    "        df[\"answer\"].value_counts().to_frame(\"NTimesWordSeenBefore\").reset_index(),\n",
    "        how=\"left\",\n",
    "    ).fillna(0)\n",
    "    X_new = X_new.groupby(\"answer\", group_keys=False).apply(\n",
    "        lambda x: x.sample(n_per_answer)\n",
    "    )\n",
    "    return X_new.reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_new = create_puzzle_options(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = total_estimator.predict_proba(X_new)\n",
    "X_new[\"probability\"] = y_pred[:, 0]\n",
    "X_new[\"probability\"].plot(kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_option(p, n):\n",
    "    return (p - p**2) ** n\n",
    "\n",
    "\n",
    "def iterative_sampling(X_new, sample_size=250, n_to_sample=100):\n",
    "    served = []\n",
    "    X_predicted = pd.DataFrame()\n",
    "    for _ in range(n_to_sample):\n",
    "        unpredicted = X_new.loc[lambda df: ~df.index.isin(X_predicted.index)]\n",
    "        if not unpredicted.empty:\n",
    "            if len(unpredicted) <= sample_size:\n",
    "                newly_predicted = unpredicted\n",
    "            else:\n",
    "                newly_predicted = unpredicted.sample(sample_size)\n",
    "            X_predicted = pd.concat([X_predicted, newly_predicted])\n",
    "        n = min(100, 5 * len(X_new) / len(X_predicted))\n",
    "        X_predicted[\"weight\"] = probability_option(X_predicted[\"probability\"], n)\n",
    "        served.append(X_predicted.sample(n=1, weights=X_predicted[\"weight\"]).squeeze())\n",
    "    return pd.concat(served, axis=\"columns\").transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_play = 100\n",
    "sample_methods = {\n",
    "    \"random\": lambda p: p.sample(n_to_play),\n",
    "    \"largest\": lambda x: x.nlargest(n_to_play, \"probability\"),\n",
    "    \"power=1\": lambda p: p.sample(\n",
    "        n_to_play, weights=probability_option(p[\"probability\"], 1)\n",
    "    ),\n",
    "    \"power=5\": lambda p: p.sample(\n",
    "        n_to_play, weights=probability_option(p[\"probability\"], 5)\n",
    "    ),\n",
    "    \"power=10\": lambda p: p.sample(\n",
    "        n_to_play, weights=probability_option(p[\"probability\"], 10)\n",
    "    ),\n",
    "    \"iterative100\": lambda p: iterative_sampling(p, 100, n_to_play),\n",
    "    \"iterative250\": lambda p: iterative_sampling(p, 250, n_to_play),\n",
    "}\n",
    "\n",
    "\n",
    "probs_played = pd.DataFrame()\n",
    "for method, func in sample_methods.items():\n",
    "    probs_played[method] = func(X_new)[\"probability\"].reset_index(drop=True)\n",
    "\n",
    "ax = probs_played.mean().sort_values().plot(kind=\"barh\")\n",
    "ax.bar_label(ax.containers[0], fmt=\"{:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_played.plot(kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine_dev.connect() as conn:\n",
    "    X_new.to_sql(\n",
    "        \"puzzleoptions\",\n",
    "        con=conn,\n",
    "        schema=\"paardensprong\",\n",
    "        if_exists=\"replace\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "    )\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine_prod.connect() as conn:\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine_prod.connect() as conn:\n",
    "    X_new.to_sql(\n",
    "        \"puzzleoptions\",\n",
    "        con=conn,\n",
    "        schema=\"paardensprong\",\n",
    "        if_exists=\"replace\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "    )\n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweevoortwaalf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
