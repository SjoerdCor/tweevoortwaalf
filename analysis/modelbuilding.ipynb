{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard, ExplainerHub\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import sklearn.metrics\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import modelbuilderpaardensprong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PLAYERNAME = os.getenv(\"playername\")\n",
    "\n",
    "database_url_prod = os.getenv(\"PROD_DATABASE_URL\").replace(\n",
    "    \"postgresql\", \"postgresql+psycopg\"\n",
    ")\n",
    "engine_prod = create_engine(database_url_prod)\n",
    "\n",
    "database_url_dev = os.getenv(\"DATABASE_URL\").replace(\"postgresql\", \"postgresql+psycopg\")\n",
    "engine_dev = create_engine(database_url_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_game(name):\n",
    "    with engine_prod.connect() as conn:\n",
    "        games = pd.read_sql_table(\"games\", conn, name, index_col=\"game_id\")\n",
    "        guesses = pd.read_sql_table(\"guesses\", conn, name, index_col=\"game_id\")\n",
    "\n",
    "    guesses_relevant = guesses.rename(columns={\"correct\": \"GuessCorrect\"})[\n",
    "        [\"guess_time\", \"GuessCorrect\"]\n",
    "    ]\n",
    "    df = (\n",
    "        games\n",
    "        # Drop games which have no guess - probably time out because of long loading times\n",
    "        .join(guesses_relevant, how=\"inner\")\n",
    "        .query(\"playername == @PLAYERNAME | game_id == 46\")\n",
    "        .assign(\n",
    "            PuzzleTimeSec=lambda df: (df[\"guess_time\"] - df[\"start_time\"]).dt.seconds,\n",
    "            # The on time is a bit strict; since you need a few seconds typing time\n",
    "            # But that's on purpose: it makes sense to train to have a bit of spare time\n",
    "            # And it helps the model since you have just a few more unsuccessfulls to train on\n",
    "            OnTime=lambda df: df[\"PuzzleTimeSec\"].lt(30),\n",
    "            Success=lambda df: df[\"GuessCorrect\"] & df[\"OnTime\"],\n",
    "            NTimesWordSeenBefore=lambda df: df.groupby(\"answer\").cumcount(),\n",
    "        )\n",
    "        # A few answers were given extremely late; probably when reconnecting\n",
    "        .query(\"PuzzleTimeSec < 120\")\n",
    "    )\n",
    "    df.columns = df.columns.map(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_paardensprong = (\n",
    "    get_data_for_game(\"paardensprong\")\n",
    "    .assign(missing_letter_index=pd.NA)\n",
    "    .astype({\"missing_letter_index\": \"Int64\"})\n",
    ")\n",
    "df_taartpuzzel = get_data_for_game(\"taartpuzzel\")\n",
    "df_paardensprong.index = pd.MultiIndex.from_product(\n",
    "    [[\"Paardensprong\"], df_paardensprong.index.astype(object)],\n",
    "    names=[\"Game\", df_paardensprong.index.name],\n",
    ")\n",
    "df_taartpuzzel.index = pd.MultiIndex.from_product(\n",
    "    [[\"Taartpuzzel\"], df_taartpuzzel.index.astype(object)],\n",
    "    names=[\"Game\", df_taartpuzzel.index.name],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols = [\n",
    "    \"start_time\",\n",
    "    \"answer\",\n",
    "    \"startpoint\",\n",
    "    \"direction\",\n",
    "    \"NTimesWordSeenBefore\",\n",
    "    \"missing_letter_index\",\n",
    "    \"Success\",\n",
    "]\n",
    "\n",
    "\n",
    "X_ps = df_paardensprong[model_cols].assign(IsTaartpuzzel=0)\n",
    "X_tp = df_taartpuzzel[model_cols].assign(IsTaartpuzzel=1)\n",
    "\n",
    "\n",
    "y_ps = X_ps.pop(\"Success\").astype(int)\n",
    "y_tp = X_tp.pop(\"Success\").astype(int)\n",
    "\n",
    "\n",
    "# Split so we can investigate results per puzzle specifically\n",
    "X_ps_train, X_ps_test, y_ps_train, y_ps_test = train_test_split(\n",
    "    X_ps, y_ps, stratify=y_ps, random_state=42\n",
    ")\n",
    "X_tp_train, X_tp_test, y_tp_train, y_tp_test = train_test_split(\n",
    "    X_tp, y_tp, stratify=y_tp, random_state=42\n",
    ")\n",
    "X_train = pd.concat([X_ps_train, X_tp_train])\n",
    "y_train = pd.concat([y_ps_train, y_tp_train])\n",
    "X_test = pd.concat([X_ps_test, X_tp_test])\n",
    "y_test = pd.concat([y_ps_test, y_tp_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(modelbuilderpaardensprong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = modelbuilderpaardensprong.pipe\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = modelbuilderpaardensprong.grid\n",
    "grid.fit(X_train, y_train)\n",
    "pipe = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_columns(columns):\n",
    "    if columns == \"all\":\n",
    "        try:\n",
    "            columns = modelbuilderpaardensprong.column_selector.columns_\n",
    "        except AttributeError:\n",
    "            modelbuilderpaardensprong.pipe.fit(X_train, y_train)\n",
    "            columns = modelbuilderpaardensprong.column_selector.columns_\n",
    "    return len(columns)\n",
    "\n",
    "\n",
    "results = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(grid.cv_results_[\"params\"]),\n",
    "        pd.Series(grid.cv_results_[\"mean_test_score\"], name=\"mean_test_score\"),\n",
    "        pd.Series(grid.cv_results_[\"mean_train_score\"], name=\"mean_train_score\"),\n",
    "        pd.Series(grid.cv_results_[\"std_test_score\"], name=\"std_test_score\"),\n",
    "    ],\n",
    "    axis=\"columns\",\n",
    ").assign(\n",
    "    Overfit=lambda df: df[\"mean_train_score\"] - df[\"mean_test_score\"],\n",
    "    columns=lambda df: df[\"columnselection__columns\"].apply(n_columns),\n",
    ")\n",
    "\n",
    "results.sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pipe.predict_proba(X_train)\n",
    "train_logloss = sklearn.metrics.log_loss(y_train, y_pred_train)\n",
    "train_auc = sklearn.metrics.roc_auc_score(y_train, y_pred_train[:, 1])\n",
    "\n",
    "y_pred_proba = pipe.predict_proba(X_ps_test)\n",
    "test_logloss = sklearn.metrics.log_loss(y_ps_test, y_pred_proba)\n",
    "test_auc = sklearn.metrics.roc_auc_score(y_ps_test, y_pred_proba[:, 1])\n",
    "\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict_proba(X_ps_test)\n",
    "dummy_logloss = sklearn.metrics.log_loss(y_ps_test, y_pred_dummy)\n",
    "dummy_auc = sklearn.metrics.roc_auc_score(y_ps_test, y_pred_dummy[:, 1])\n",
    "\n",
    "print(\"Log loss:\")\n",
    "print(\" Train - Test  -  Dummy\")\n",
    "print(f\"{train_logloss: .3f} - {test_logloss:.3f} - {dummy_logloss: .3f}\")\n",
    "\n",
    "print(\"AUC:\")\n",
    "print(\" Train - Test  -  Dummy\")\n",
    "print(f\"{train_auc: .3f} - {test_auc:.3f} - {dummy_auc: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = pipe.predict_proba(X_tp_test)\n",
    "test_logloss = sklearn.metrics.log_loss(y_tp_test, y_pred_proba)\n",
    "test_auc = sklearn.metrics.roc_auc_score(y_tp_test, y_pred_proba[:, 1])\n",
    "\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict_proba(X_tp_test)\n",
    "dummy_logloss = sklearn.metrics.log_loss(y_tp_test, y_pred_dummy)\n",
    "dummy_auc = sklearn.metrics.roc_auc_score(y_tp_test, y_pred_dummy[:, 1])\n",
    "\n",
    "print(\"Log loss:\")\n",
    "print(\" Train - Test  -  Dummy\")\n",
    "print(f\"{train_logloss: .3f} - {test_logloss:.3f} - {dummy_logloss: .3f}\")\n",
    "\n",
    "print(\"AUC:\")\n",
    "print(\" Train - Test  -  Dummy\")\n",
    "print(f\"{train_auc: .3f} - {test_auc:.3f} - {dummy_auc: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_tot = ClassifierExplainer(pipe, X_test, y_test, pos_label=0)\n",
    "db_tot = ExplainerDashboard(explainer_tot, title=\"Combined\", name=\"combined\")\n",
    "explainer_ps = ClassifierExplainer(pipe, X_ps_test, y_ps_test, pos_label=0)\n",
    "db_ps = ExplainerDashboard(explainer_ps, title=\"Paardensprong\", name=\"paardensprong\")\n",
    "explainer_tp = ClassifierExplainer(pipe, X_tp_test, y_tp_test, pos_label=0)\n",
    "db_tp = ExplainerDashboard(explainer_tp, title=\"Taartpuzzel\", name=\"taartpuzzel\")\n",
    "hub = ExplainerHub([])\n",
    "hub.add_dashboard(db_tot)\n",
    "hub.add_dashboard(db_ps)\n",
    "hub.add_dashboard(db_tp)\n",
    "hub.run(host=\"127.0.0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit final model\n",
    "Fit on total set to use all data, do some quick fatal flaw inspection on probabilities and logical relations between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_estimator = clone(pipe)\n",
    "X = pd.concat([X_ps_train, X_ps_test, X_tp_train, X_tp_test])\n",
    "y = pd.concat([y_ps_train, y_ps_test, y_tp_train, y_tp_test])\n",
    "total_estimator.fit(X, y)\n",
    "\n",
    "X_transformed = X.copy()\n",
    "for transformer in total_estimator.steps[:-1]:\n",
    "    X_transformed = transformer[1].transform(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(total_estimator.predict_proba(X)[:, 0]).plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PartialDependenceDisplay.from_estimator(\n",
    "    total_estimator.named_steps[\"clf\"],\n",
    "    X_transformed,\n",
    "    features=range(len(X_transformed.columns)),\n",
    "    kind=\"both\",\n",
    ")\n",
    "\n",
    "\n",
    "display.plot(pdp_lim={1: (0.8, 1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_taartpuzzels():\n",
    "    words = pd.read_csv(\n",
    "        \"../tweevoortwaalf/Data/suitable_9_letter_words.txt\", header=None\n",
    "    ).squeeze()\n",
    "\n",
    "    startpoint = range(9)\n",
    "    missing_letter_index = range(9)\n",
    "    directions = [-1, 1]\n",
    "\n",
    "    X_new = pd.DataFrame(\n",
    "        itertools.product(words, startpoint, directions, missing_letter_index),\n",
    "        columns=[\"answer\", \"startpoint\", \"direction\", \"missing_letter_index\"],\n",
    "    ).assign(start_time=pd.Timestamp.now(), IsTaartpuzzel=1)\n",
    "    return X_new\n",
    "\n",
    "\n",
    "def generate_all_paardensprongen():\n",
    "    words = pd.read_csv(\n",
    "        \"../tweevoortwaalf/Data/suitable_8_letter_words.txt\", header=None\n",
    "    ).squeeze()\n",
    "    startpoint = range(8)\n",
    "    directions = [-1, 1]\n",
    "\n",
    "    X_new = pd.DataFrame(\n",
    "        itertools.product(words, startpoint, directions),\n",
    "        columns=[\"answer\", \"startpoint\", \"direction\"],\n",
    "    ).assign(start_time=pd.Timestamp.now(), IsTaartpuzzel=0)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_puzzle_options(X_new, n_per_answer=4):\n",
    "    ntimeswordseenbefore = (\n",
    "        X[\"answer\"].value_counts().to_frame(\"NTimesWordSeenBefore\").reset_index()\n",
    "    )\n",
    "\n",
    "    X_new = (\n",
    "        X_new.merge(ntimeswordseenbefore, how=\"left\")\n",
    "        .fillna({\"NTimesWordSeenBefore\": 0})\n",
    "        .groupby(\"answer\", group_keys=False)\n",
    "        .apply(lambda x: x.sample(n_per_answer))\n",
    "    )\n",
    "\n",
    "    return X_new.reset_index(drop=True)\n",
    "\n",
    "\n",
    "taartpuzzel_options = generate_all_taartpuzzels().pipe(create_puzzle_options)\n",
    "paardensprong_options = generate_all_paardensprongen().pipe(create_puzzle_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tp = total_estimator.predict_proba(taartpuzzel_options)\n",
    "taartpuzzel_options[\"probability\"] = y_pred_tp[:, 0]\n",
    "\n",
    "y_pred_ps = total_estimator.predict_proba(paardensprong_options)\n",
    "paardensprong_options[\"probability\"] = y_pred_ps[:, 0]\n",
    "taartpuzzel_options[\"probability\"].plot(kind=\"kde\", label=\"Taartpuzzel\")\n",
    "paardensprong_options[\"probability\"].plot(kind=\"kde\", label=\"Paardensprong\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_puzzle_options(df, name, engine):\n",
    "    with engine.connect() as conn:\n",
    "        df.to_sql(\n",
    "            \"puzzleoptions\",\n",
    "            con=conn,\n",
    "            schema=name,\n",
    "            if_exists=\"replace\",\n",
    "            index=False,\n",
    "            method=\"multi\",\n",
    "            chunksize=4000,\n",
    "        )\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "write_puzzle_options(taartpuzzel_options, \"taartpuzzel\", engine_dev)\n",
    "write_puzzle_options(taartpuzzel_options, \"taartpuzzel\", engine_prod)\n",
    "write_puzzle_options(paardensprong_options, \"paardensprong\", engine_dev)\n",
    "write_puzzle_options(paardensprong_options, \"paardensprong\", engine_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine_prod.connect() as conn:\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick investigation in sampling methods\n",
    "Which method strikes a good balance between exploitation and exploration:\n",
    "enough balancing so that it is surprising and learns new things, yet also the user gets hard enough puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_option(p, n):\n",
    "    return (p - p**2) ** n\n",
    "\n",
    "\n",
    "def iterative_sampling(X_new, sample_size=250, n_to_sample=100):\n",
    "    served = []\n",
    "    X_predicted = pd.DataFrame()\n",
    "    for _ in range(n_to_sample):\n",
    "        unpredicted = X_new.loc[lambda df: ~df.index.isin(X_predicted.index)]\n",
    "        if not unpredicted.empty:\n",
    "            if len(unpredicted) <= sample_size:\n",
    "                newly_predicted = unpredicted\n",
    "            else:\n",
    "                newly_predicted = unpredicted.sample(sample_size)\n",
    "            X_predicted = pd.concat([X_predicted, newly_predicted])\n",
    "        n = min(100, 5 * len(X_new) / len(X_predicted))\n",
    "        X_predicted[\"weight\"] = probability_option(X_predicted[\"probability\"], n)\n",
    "        served.append(X_predicted.sample(n=1, weights=X_predicted[\"weight\"]).squeeze())\n",
    "    return pd.concat(served, axis=\"columns\").transpose()\n",
    "\n",
    "\n",
    "n_to_play = 100\n",
    "sample_methods = {\n",
    "    \"random\": lambda p: p.sample(n_to_play),\n",
    "    \"largest\": lambda x: x.nlargest(n_to_play, \"probability\"),\n",
    "    \"power=1\": lambda p: p.sample(\n",
    "        n_to_play, weights=probability_option(p[\"probability\"], 1)\n",
    "    ),\n",
    "    \"power=5\": lambda p: p.sample(\n",
    "        n_to_play, weights=probability_option(p[\"probability\"], 5)\n",
    "    ),\n",
    "    \"power=10\": lambda p: p.sample(\n",
    "        n_to_play, weights=probability_option(p[\"probability\"], 10)\n",
    "    ),\n",
    "    \"iterative100\": lambda p: iterative_sampling(p, 100, n_to_play),\n",
    "    \"iterative250\": lambda p: iterative_sampling(p, 250, n_to_play),\n",
    "}\n",
    "\n",
    "\n",
    "probs_played = pd.DataFrame()\n",
    "for method, func in sample_methods.items():\n",
    "    probs_played[method] = func(taartpuzzel_options)[\"probability\"].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "ax = probs_played.mean().sort_values().plot(kind=\"barh\")\n",
    "ax.bar_label(ax.containers[0], fmt=\"{:.1%}\")\n",
    "probs_played.plot(kind=\"kde\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweevoortwaalf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
