{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taartpuzzel\n",
    "The goal of this notebook is to do the exploratory analysis needed to build a model that can predict the probability of a correct and timely guess. \n",
    "I want to use that model to select puzzles which I have a ~50% chance of solving\n",
    "\n",
    "* Theoretical model:\n",
    "  * Basic puzzle:\n",
    "    * Finding direction in the word\n",
    "    * Finding starting point in the word\n",
    "\n",
    "  * Recognizing the word\n",
    "    * Word frequency in normal language\n",
    "    * Having seen it recently (in a puzzle) \n",
    "    * Experience - I expect I get better over time\n",
    "    * Pronunciation matches writing it down (e.g. fauteuil is very hard) - not implemented yet\n",
    "\n",
    "  * Puzzle (inadvertent biases from my starting point, so that I take too long to switch to the correct point)\n",
    "    * Direction \n",
    "    * Starting point\n",
    "    * And sometimes I lose track when a single letter occurs very frequently - not implemented yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import importlib.resources\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PLAYERNAME = os.getenv(\"playername\")\n",
    "\n",
    "database_url_prod = os.getenv(\"PROD_DATABASE_URL\").replace(\n",
    "    \"postgresql\", \"postgresql+psycopg\"\n",
    ")\n",
    "engine_prod = create_engine(database_url_prod)\n",
    "\n",
    "database_url_dev = os.getenv(\"DATABASE_URL\").replace(\"postgresql\", \"postgresql+psycopg\")\n",
    "engine_dev = create_engine(database_url_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine_prod.connect() as conn:\n",
    "    games = pd.read_sql_query(\n",
    "        \"SELECT * FROM taartpuzzel.games\", con=conn, index_col=\"game_id\"\n",
    "    )\n",
    "    guesses = pd.read_sql_query(\n",
    "        \"SELECT * FROM taartpuzzel.guesses\", con=conn, index_col=\"guess_id\"\n",
    "    )\n",
    "\n",
    "guesses_relevant = guesses.set_index(\"game_id\").rename(\n",
    "    columns={\"correct\": \"GuessCorrect\"}\n",
    ")[[\"guess_time\", \"GuessCorrect\"]]\n",
    "\n",
    "df = (\n",
    "    games\n",
    "    # Drop games which have no guess - probably time out because of long loading times\n",
    "    .join(guesses_relevant, how=\"inner\")\n",
    "    .query(\"playername == @PLAYERNAME\")\n",
    "    .assign(\n",
    "        PuzzleTimeSec=lambda df: (df[\"guess_time\"] - df[\"start_time\"]).dt.seconds,\n",
    "        # The on time is a bit strict; since you need a few seconds typing time\n",
    "        # But that's on purpose: it makes sense to train to have a bit of spare time\n",
    "        # And it helps the model since you have just a few more unsuccessfulls to train on\n",
    "        OnTime=lambda df: df[\"PuzzleTimeSec\"].lt(30),\n",
    "        Success=lambda df: df[\"GuessCorrect\"] & df[\"OnTime\"],\n",
    "    )\n",
    "    # A few answers were given extremely late; probably when reconnecting\n",
    "    .query(\"PuzzleTimeSec < 120\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_word(row):\n",
    "    mli = row[\"missing_letter_index\"]\n",
    "    return row[\"answer\"][mli + 1 :] + row[\"answer\"][:mli]\n",
    "\n",
    "\n",
    "df[\"continuous_word\"] = df.apply(continuous_word, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we immediately see the problem: ~90% is solved successfully on time; so I want the most challenging puzzles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Success\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PuzzleTimeSec\"].hist(bins=range(0, df[\"PuzzleTimeSec\"].max() + 5, 5))\n",
    "df[\"PuzzleTimeSec\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = importlib.resources.files(\"tweevoortwaalf.Data\").joinpath(\n",
    "    \"suitable_9_letter_words.txt\"\n",
    ")\n",
    "nineletterwords = pd.read_csv(DATA_PATH, header=None).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While solving the puzzle, I often look for illogical consecutive letters. Then we know that can't be correct, so the solution should go the other way around. First, we generalize this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(2, 2))\n",
    "vectorizer.fit(nineletterwords)\n",
    "ngrams_occurences_total = vectorizer.transform(nineletterwords).toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_letters = nineletterwords.str[-1].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyness_score(woord, vectorizer=vectorizer):\n",
    "    \"Sums all transitions of letters -> the higher, the more logical\"\n",
    "    ngrams_occurences_word = vectorizer.transform([woord]).toarray()\n",
    "    return (ngrams_occurences_word * ngrams_occurences_total).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direction\n",
    "* To find the logical direction, you check the second least likely transition per direction. \n",
    "* The least likely transition of two characters would be the word boundary\n",
    "* If there is another one, then perhaps the word is not written in that direction\n",
    "* Then, we compare the second least likely transition per direction. \n",
    "\n",
    "\n",
    "This could probably be improved by explicitly checking the least likely transition is a likely word boundary (e.g. zwerfkei: wz is illogical transition AND ew is impossible end of word, even though \"ziek\"  is a good start of word). The newer version (not implemented in the model yet) tried to this by checking how common the last letter is, and checkign the least likely \"transition\" (word boundary or transition). This didn't improve it much, probably because the combination of two last letters says more (see the exmaple), but that requires some thinking on how to compare transtions with two letter endings - are these the same on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_single_direction_original(word, circular=True):\n",
    "    \"\"\"Check the second least likely transition, including the transition across the word boundary\"\"\"\n",
    "    if circular:\n",
    "        word = word + word[0]\n",
    "    logical = []\n",
    "    for i in range(len(word) - 1):\n",
    "        logical.append(easyness_score(word[i] + word[i + 1]))\n",
    "    return sorted(logical)[1]\n",
    "\n",
    "\n",
    "def logical_correct_direction_original(word, circular=True, compensation=0.5):\n",
    "    \"\"\"Compare both directions\n",
    "\n",
    "    compensation to prevent division by zero\n",
    "    \"\"\"\n",
    "    logical_actual_direction = logical_single_direction_original(word, circular)\n",
    "    logical_wrong_direction = logical_single_direction_original(word[::-1], circular)\n",
    "    return (logical_actual_direction + compensation) / (\n",
    "        logical_wrong_direction + compensation\n",
    "    )\n",
    "\n",
    "\n",
    "direction = df[\"answer\"].apply(logical_correct_direction_original)\n",
    "directionbins = pd.qcut(direction, q=5)\n",
    "display(df.groupby(directionbins)[\"Success\"].agg([\"count\", \"mean\"]))\n",
    "\n",
    "direction_noncircular = df[\"continuous_word\"].apply(\n",
    "    logical_correct_direction_original, circular=False\n",
    ")\n",
    "directionbins_noncircular = pd.qcut(direction_noncircular, q=5)\n",
    "display(df.groupby(directionbins_noncircular)[\"Success\"].agg([\"count\", \"mean\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_single_direction(word):\n",
    "    \"\"\"Check the second least likely transition, including the transition across the word boundary\"\"\"\n",
    "    circular_word = word + word[0]\n",
    "    logical = []\n",
    "    for i in range(len(circular_word) - 1):\n",
    "        logical.append(easyness_score(circular_word[i] + circular_word[i + 1]))\n",
    "    least_likely_index = np.argmin(logical)\n",
    "    poss_wordboundary = end_letters.get(circular_word[least_likely_index], 0)\n",
    "    return min(sorted(logical)[1], poss_wordboundary)\n",
    "\n",
    "\n",
    "def logical_correct_direction(word, compensation=0.5):\n",
    "    \"\"\"Compare both directions\"\"\"\n",
    "    logical_actual_direction = logical_single_direction(word)\n",
    "    logical_wrong_direction = logical_single_direction(word[::-1])\n",
    "    return (logical_actual_direction + compensation) / (\n",
    "        logical_wrong_direction + compensation\n",
    "    )\n",
    "\n",
    "\n",
    "df[\"answerDirectionLogical\"] = df[\"answer\"].apply(logical_correct_direction)\n",
    "directionbins = pd.qcut(df[\"answerDirectionLogical\"], q=5)\n",
    "df.groupby(directionbins)[\"Success\"].agg([\"count\", \"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed we see that words where the direction is clear are more often guessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.nsmallest(5, \"answerDirectionLogical\"))\n",
    "display(df.sample(20).sort_values(\"answerDirectionLogical\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word boundary\n",
    "Assuming the correct direction, how special is the actual transition of the word boundary compared to the other character transitions?\n",
    "This is not perfect yet.. e.g. ox and xi are special in oxidator, but that doesnt make the X the logical starting letter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_word_boundary(word, compensation=0.5, circular=True):\n",
    "    circular_word = word + word[0]\n",
    "    logical = []\n",
    "    for i in range(len(circular_word) - 1):\n",
    "        logical.append(\n",
    "            1 / (easyness_score(circular_word[i] + circular_word[i + 1]) + compensation)\n",
    "        )\n",
    "    return logical[-1] / sum(logical)\n",
    "\n",
    "\n",
    "df[\"answerBoundaryLogical\"] = df[\"continuous_word\"].apply(\n",
    "    logical_word_boundary, circular=False\n",
    ")\n",
    "wordboundarybins = pd.qcut(df[\"answerBoundaryLogical\"], q=5)\n",
    "display(df.groupby(wordboundarybins)[\"Success\"].agg([\"count\", \"mean\"]))\n",
    "\n",
    "df[\"answerBoundaryLogical\"] = df[\"answer\"].apply(logical_word_boundary)\n",
    "wordboundarybins = pd.qcut(df[\"answerBoundaryLogical\"], q=5)\n",
    "df.groupby(wordboundarybins)[\"Success\"].agg([\"count\", \"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.nsmallest(5, \"answerBoundaryLogical\"))\n",
    "display(df.sample(20).sort_values(\"answerBoundaryLogical\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How logical is the letter under the \"?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurence_ngrams(ngram_length=1, wordlist=nineletterwords):\n",
    "    cv = CountVectorizer(analyzer=\"char_wb\", ngram_range=(ngram_length, ngram_length))\n",
    "    occurences = cv.fit_transform(wordlist)\n",
    "    df = pd.DataFrame(occurences.toarray(), columns=cv.get_feature_names_out()).rename(\n",
    "        columns=lambda s: s.replace(\" \", \"_\")\n",
    "    )\n",
    "    return df.sum()\n",
    "\n",
    "\n",
    "def calculate_odds_letters():\n",
    "\n",
    "    twograms = get_occurence_ngrams(2)\n",
    "    twograms.index = pd.MultiIndex.from_arrays(\n",
    "        [twograms.index.str[0], twograms.index.str[1]],\n",
    "        names=[\"FirstLetter\", \"SecondLetter\"],\n",
    "    )\n",
    "\n",
    "    odds = twograms.to_frame(\"Occurrences\").assign(\n",
    "        PercentageSecondLetterGivenFirst=lambda df: df[\"Occurrences\"]\n",
    "        / df.groupby(\"FirstLetter\")[\"Occurrences\"].sum(),\n",
    "        PercentageFirstLetterGivenSecond=lambda df: df[\"Occurrences\"]\n",
    "        / df.groupby(\"SecondLetter\")[\"Occurrences\"].sum(),\n",
    "    )\n",
    "    return odds\n",
    "\n",
    "\n",
    "def extract_letters(row):\n",
    "    index = row[\"missing_letter_index\"]\n",
    "    answer = row[\"answer\"]\n",
    "\n",
    "    letter_before = answer[index - 1] if index > 0 else \"_\"\n",
    "    letter_missing = answer[index]\n",
    "    letter_after = answer[index + 1] if index < len(answer) - 1 else \"_\"\n",
    "\n",
    "    return pd.Series([letter_before, letter_missing, letter_after])\n",
    "\n",
    "\n",
    "df[[\"LetterBefore\", \"LetterMissing\", \"LetterAfter\"]] = df.apply(extract_letters, axis=1)\n",
    "\n",
    "odds = calculate_odds_letters()\n",
    "df_inc_probs = df.merge(\n",
    "    odds[[\"PercentageSecondLetterGivenFirst\"]],\n",
    "    how=\"left\",\n",
    "    left_on=[\"LetterBefore\", \"LetterMissing\"],\n",
    "    right_index=True,\n",
    ").merge(\n",
    "    odds[[\"PercentageFirstLetterGivenSecond\"]],\n",
    "    how=\"left\",\n",
    "    left_on=[\"LetterMissing\", \"LetterAfter\"],\n",
    "    right_index=True,\n",
    ")\n",
    "df[\"MaxPercentageProbableLetter\"] = df_inc_probs[\n",
    "    [\"PercentageSecondLetterGivenFirst\", \"PercentageFirstLetterGivenSecond\"]\n",
    "].max(\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentbins = pd.qcut(df[\"MaxPercentageProbableLetter\"], q=5)\n",
    "display(df.groupby(percentbins)[\"Success\"].agg([\"count\", \"mean\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowing word\n",
    "I hypothesize that recognizing the word is easier if you have seen the word recently. That would be related to how often you see it in normal use of the language, and whether it was played recently (which is not implemented yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = pd.read_csv(\"../tweevoortwaalf/Data/wordlist.csv\")\n",
    "# There are some duplicates in Word for words including ij, where one occurs very infrequently\n",
    "frequency = wordlist.query(\"Length == 9\").groupby(\"Word\")[\"Frequency\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(frequency, left_on=\"answer\", right_index=True)\n",
    "frequencybins = pd.qcut(df[\"Frequency\"], q=5)\n",
    "df.groupby(frequencybins)[\"Success\"].agg([\"count\", \"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.nsmallest(5, \"Frequency\"))\n",
    "display(df.sample(20).sort_values(\"Frequency\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed the least frequent words are guessed less often - this is in line with the hypothesis that especially the words that you don't know are much harder. However, the frequency is far from a perfect indicator, where from experience I think this should be very important. E.g. bakplaat and pijngrens are less used than hypofyse or bordeaux?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Times word seen before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nseenbefore = df.groupby(\"answer\").cumcount()\n",
    "df.groupby(nseenbefore)[\"Success\"].agg([\"count\", \"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle: startpoint\n",
    "I'm not convinced the puzzle characteristics will have a strong effect; I think the word is more important. But it would be silly to rule out my own biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"startpoint\")[\"Success\"].agg([\"count\", \"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this data, it's definitely impossible to rule out the hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"missing_letter_index\")[\"Success\"].agg([\"count\", \"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle: direction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"direction\")[\"Success\"].agg([\"count\", \"sum\", \"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience\n",
    "I expect that I get better and better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index().assign(Fail=lambda df: ~df[\"Success\"])[\"Fail\"].rolling(100).mean().plot(\n",
    "    ylim=(0, None)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweevoortwaalf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
